import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

car_data = pd.read_csv("car data.csv")

print(car_data.info())
print(car_data.isnull().sum())
print(car_data.describe())

car_data.drop(columns=['Car_Name'], inplace=True)

# car age
car_data['Car_Age'] = 2024 - car_data['Year']
car_data.drop(columns=['Year'], inplace=True)

# encoding
categorical_features = ['Fuel_Type', 'Selling_type', 'Transmission']
encoder = OneHotEncoder(drop='first', sparse_output=False)  # Use sparse_output instead of sparse
encoded_features = pd.DataFrame(
    encoder.fit_transform(car_data[categorical_features]),
    columns=encoder.get_feature_names_out(categorical_features)
)
car_data = pd.concat([car_data.drop(columns=categorical_features), encoded_features], axis=1)

X = car_data.drop(columns=['Selling_Price'])
y = car_data['Selling_Price']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-Squared: {r2}")
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.xlabel('Actual Selling Price')
plt.ylabel('Predicted Selling Price')
plt.title('Actual vs Predicted Selling Price')
plt.show()
